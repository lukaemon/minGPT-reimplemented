{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp \n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from general.utils import ModelConfig, TrainConfig\n",
    "from jax_impl.model import *\n",
    "import optax\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'config_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m key \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mPRNGKey(\u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model_config \u001b[39m=\u001b[39m ModelConfig(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     vocab_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     context_window\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt-nano\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu_remote_host/home/lucas/Dev/minGPT-reimplemented/jax_demo.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model_config\n",
      "File \u001b[0;32m<string>:12\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, context_window, n_embd, n_head, n_layer, model_type, attn_pdrop, recid_pdrop, embd_pdrop)\u001b[0m\n",
      "File \u001b[0;32m~/Dev/minGPT-reimplemented/general/utils.py:32\u001b[0m, in \u001b[0;36mModelConfig.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__post_init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_set \u001b[39m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m         \u001b[39m# names follow the huggingface naming conventions\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         \u001b[39m# GPT-1\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mopenai-gpt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m768\u001b[39m),  \u001b[39m# 117M params\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# GPT-2 configs\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m768\u001b[39m),  \u001b[39m# 124M params\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt2-medium\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m),  \u001b[39m# 350M params\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt2-large\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m36\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m1280\u001b[39m),  \u001b[39m# 774M params\u001b[39;00m\n\u001b[1;32m     40\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt2-xl\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m1600\u001b[39m),  \u001b[39m# 1558M params\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[39m# Gophers\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgopher-44m\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m),\n\u001b[1;32m     43\u001b[0m         \u001b[39m# (there are a number more...)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         \u001b[39m# I made these tiny models up\u001b[39;00m\n\u001b[1;32m     45\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt-mini\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m192\u001b[39m),\n\u001b[1;32m     46\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt-micro\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m),\n\u001b[1;32m     47\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgpt-nano\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(n_layer\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_head\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_embd\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m),\n\u001b[1;32m     48\u001b[0m     }\n\u001b[1;32m     50\u001b[0m     params_given \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_embd, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layer])\n\u001b[1;32m     51\u001b[0m     type_given \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'config_set'"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(42)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    vocab_size=1024, \n",
    "    context_window=64, \n",
    "    model_type='gpt-nano')\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx, rp, rd, key = random.split(key, 4)\n",
    "init_rngs = {'params': rp, 'dropout': rd}\n",
    "\n",
    "x = random.normal(rx, (10, 4, 48))\n",
    "\n",
    "attn = Attention(model_config)\n",
    "params = attn.init(init_rngs, x)\n",
    "\n",
    "out = attn.apply(params, x, rngs={'dropout': rd})\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = Block(model_config)\n",
    "params = blk.init(init_rngs, x)\n",
    "\n",
    "output = blk.apply(params, x, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(rx, (10, 4), 0, maxval=model_config.vocab_size, dtype=jnp.integer)\n",
    "\n",
    "emb = Embedding(model_config)\n",
    "params = emb.init(init_rngs, idx)\n",
    "\n",
    "output = emb.apply(params, idx, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(model_config)\n",
    "params = gpt.init(init_rngs, idx)\n",
    "\n",
    "output = gpt.apply(params, idx, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general.dataset import SortDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def numpy_collate(batch):\n",
    "  if isinstance(batch[0], np.ndarray):\n",
    "    return np.stack(batch)\n",
    "  elif isinstance(batch[0], (tuple,list)):\n",
    "    transposed = zip(*batch)\n",
    "    return [numpy_collate(samples) for samples in transposed]\n",
    "  else:\n",
    "    return np.array(batch)\n",
    "\n",
    "def cast(x):\n",
    "    return np.array(x, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SortDataset('train', num_digits=6, transform=cast)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    vocab_size=6, \n",
    "    context_window=16, \n",
    "    model_type='gpt-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(model_config)\n",
    "params = gpt.init(init_rngs, idx)\n",
    "\n",
    "logits = gpt.apply(params, x, rngs={'dropout': rd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.take_along_axis(logits, y[...,None], axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.take_along_axis(logits, y[...,None], axis=-1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[y!= -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y!=-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels, ignore_index=-1):\n",
    "    filter = labels != ignore_index\n",
    "    labels = labels[filter]\n",
    "    logits = logits[filter]\n",
    "\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels)\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_impl.train import create_train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(key, model_config, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_impl.train import train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(key, state, batch, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2197b825b7386dfddab0fbacf6c0b51d2279ad2fcc5a7725cfa6cd332434469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
