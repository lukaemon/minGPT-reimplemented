{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp \n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from general.utils import ModelConfig\n",
    "from jax_impl.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(vocab_size=1024, context_window=64, n_embd=48, n_head=3, n_layer=3, model_type='gpt-nano', attn_pdrop=0.1, recid_pdrop=0.1, embd_pdrop=0.1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = random.PRNGKey(42)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    vocab_size=1024, \n",
    "    context_window=64, \n",
    "    model_type='gpt-nano')\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx, rp, rd, key = random.split(key, 4)\n",
    "init_rngs = {'params': rp, 'dropout': rd}\n",
    "\n",
    "x = random.normal(rx, (10, 4, 48))\n",
    "\n",
    "attn = Attention(model_config)\n",
    "params = attn.init(init_rngs, x)\n",
    "\n",
    "out = attn.apply(params, x, rngs={'dropout': rd})\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Block(model_config)\n",
    "params = blk.init(init_rngs, x)\n",
    "\n",
    "output = blk.apply(params, x, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(rx, (10, 4), 0, maxval=model_config.vocab_size, dtype=jnp.integer)\n",
    "\n",
    "emb = Embedding(model_config)\n",
    "params = emb.init(init_rngs, idx)\n",
    "\n",
    "output = emb.apply(params, idx, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPT(model_config)\n",
    "params = gpt.init(init_rngs, idx)\n",
    "\n",
    "output = gpt.apply(params, idx, rngs={'dropout': rd})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    GPT Summary                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path                          </span>┃<span style=\"font-weight: bold\"> outputs            </span>┃<span style=\"font-weight: bold\"> params                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs                        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[10,4]        │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dense_0   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,144]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[144]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">7,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(28.2 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dense_1   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">2,352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(9.4 KB)</span>              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dropout_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dense_0               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,192]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.6 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dense_1               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,264 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dense_0   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,144]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[144]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">7,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(28.2 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dense_1   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">2,352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(9.4 KB)</span>              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dropout_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dense_0               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,192]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.6 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dense_1               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,264 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dense_0   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,144]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[144]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">7,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(28.2 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dense_1   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">2,352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(9.4 KB)</span>              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dropout_0 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dense_0               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,192]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192]          │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,408 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.6 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dense_1               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">9,264 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Dense_0                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,1024] │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024]         │\n",
       "│                               │                    │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48,1024]    │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">50,176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(200.7 KB)</span>           │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Dropout_0         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Embed_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,48]      │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,48]   │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">3,072 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(12.3 KB)</span>             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Embed_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1024,48] │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">49,152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(196.6 KB)</span>           │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ LayerNorm_0                   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,48]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]           │\n",
       "│                               │                    │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ <span style=\"font-weight: bold\">96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(384 B)</span>                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ GPT                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[10,4,1024] │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">                               </span>│<span style=\"font-weight: bold\">              Total </span>│<span style=\"font-weight: bold\"> 187,312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(749.2 KB)</span><span style=\"font-weight: bold\">          </span>│\n",
       "└───────────────────────────────┴────────────────────┴─────────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                    </span>\n",
       "<span style=\"font-weight: bold\">                        Total Parameters: 187,312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(749.2 KB)</span><span style=\"font-weight: bold\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    GPT Summary                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath                         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs                        │ \u001b[2mint32\u001b[0m[10,4]        │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dense_0   │ \u001b[2mfloat32\u001b[0m[10,4,144]  │ bias: \u001b[2mfloat32\u001b[0m[144]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m7,056 \u001b[0m\u001b[1;2m(28.2 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dense_1   │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m2,352 \u001b[0m\u001b[1;2m(9.4 KB)\u001b[0m              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0/Dropout_0 │ \u001b[2mfloat32\u001b[0m[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Attention_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dense_0               │ \u001b[2mfloat32\u001b[0m[10,4,192]  │ bias: \u001b[2mfloat32\u001b[0m[192]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,408 \u001b[0m\u001b[1;2m(37.6 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dense_1               │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,264 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/Dropout_0             │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_0                       │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dense_0   │ \u001b[2mfloat32\u001b[0m[10,4,144]  │ bias: \u001b[2mfloat32\u001b[0m[144]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m7,056 \u001b[0m\u001b[1;2m(28.2 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dense_1   │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m2,352 \u001b[0m\u001b[1;2m(9.4 KB)\u001b[0m              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0/Dropout_0 │ \u001b[2mfloat32\u001b[0m[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Attention_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dense_0               │ \u001b[2mfloat32\u001b[0m[10,4,192]  │ bias: \u001b[2mfloat32\u001b[0m[192]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,408 \u001b[0m\u001b[1;2m(37.6 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dense_1               │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,264 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/Dropout_0             │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_1                       │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dense_0   │ \u001b[2mfloat32\u001b[0m[10,4,144]  │ bias: \u001b[2mfloat32\u001b[0m[144]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,144]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m7,056 \u001b[0m\u001b[1;2m(28.2 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dense_1   │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,48]      │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m2,352 \u001b[0m\u001b[1;2m(9.4 KB)\u001b[0m              │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0/Dropout_0 │ \u001b[2mfloat32\u001b[0m[10,3,4,4]  │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Attention_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dense_0               │ \u001b[2mfloat32\u001b[0m[10,4,192]  │ bias: \u001b[2mfloat32\u001b[0m[192]          │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,192]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,408 \u001b[0m\u001b[1;2m(37.6 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dense_1               │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[192,48]     │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m9,264 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/Dropout_0             │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Block_2                       │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Dense_0                       │ \u001b[2mfloat32\u001b[0m[10,4,1024] │ bias: \u001b[2mfloat32\u001b[0m[1024]         │\n",
       "│                               │                    │ kernel: \u001b[2mfloat32\u001b[0m[48,1024]    │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m50,176 \u001b[0m\u001b[1;2m(200.7 KB)\u001b[0m           │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Dropout_0         │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Embed_0           │ \u001b[2mfloat32\u001b[0m[4,48]      │ embedding: \u001b[2mfloat32\u001b[0m[64,48]   │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m3,072 \u001b[0m\u001b[1;2m(12.3 KB)\u001b[0m             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0/Embed_1           │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ embedding: \u001b[2mfloat32\u001b[0m[1024,48] │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m49,152 \u001b[0m\u001b[1;2m(196.6 KB)\u001b[0m           │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ Embedding_0                   │ \u001b[2mfloat32\u001b[0m[10,4,48]   │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ LayerNorm_0                   │ \u001b[2mfloat32\u001b[0m[10,4,48]   │ bias: \u001b[2mfloat32\u001b[0m[48]           │\n",
       "│                               │                    │ scale: \u001b[2mfloat32\u001b[0m[48]          │\n",
       "│                               │                    │                             │\n",
       "│                               │                    │ \u001b[1m96 \u001b[0m\u001b[1;2m(384 B)\u001b[0m                  │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│ GPT                           │ \u001b[2mfloat32\u001b[0m[10,4,1024] │                             │\n",
       "├───────────────────────────────┼────────────────────┼─────────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m                             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m187,312 \u001b[0m\u001b[1;2m(749.2 KB)\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\n",
       "└───────────────────────────────┴────────────────────┴─────────────────────────────┘\n",
       "\u001b[1m                                                                                    \u001b[0m\n",
       "\u001b[1m                        Total Parameters: 187,312 \u001b[0m\u001b[1;2m(749.2 KB)\u001b[0m\u001b[1m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gpt.tabulate(init_rngs, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2197b825b7386dfddab0fbacf6c0b51d2279ad2fcc5a7725cfa6cd332434469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
